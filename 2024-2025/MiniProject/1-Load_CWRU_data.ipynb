{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e254f2",
   "metadata": {},
   "source": [
    "<span style=\"font-size:10pt\">AI-ML @ ENSPIMA / v1.3 september 2024 / Jean-Luc CHARLES (Jean-Luc.charles@mailo.com) / CC BY-SA 4.0 /</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd770de",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"color:brown;font-family:arial;font-size:26pt;font-weight:bold;text-align:center\"> \n",
    "Machine Learning $-$ MiniProject</div><br>\n",
    "<hr>\n",
    "<div style=\"color:blue;font-family:arial;font-size:22pt;font-weight:bold;text-align:center\">\n",
    "Training a neural network to diagnose bearing faults<br><br>\n",
    "Part 1/3: Load the CWRU (Case Western Reserve University)<br><br>bearing dataset</div>\n",
    "<hr>\n",
    "Expected duration : 60 minutes (may depend on Internet rate if you choose to download the dataset from Internet)\n",
    "\n",
    "## Part-1 targeted learning objectives\n",
    "Know how to:\n",
    "- load files in *Matlab MAT-file* format with *Python*.\n",
    "- dimension and fill numpy ndarrays with the data of the `.mat` files\n",
    "- display a grid of data plots\n",
    "- store the numpy ndarrays in a `.npz` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d6055c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<span style=\"color:brown;font-family:arial;font-size:12pt\"> \n",
    "It is important to use a <span style=\"font-weight:bold;\">Python Virtual Environment</span> (PVE) for your Python projects: a PVE makes it possible to control for each project the versions of the Python interpreter and the \"sensitive\" modules (like tensorflow).\n",
    "    \n",
    "All the notebooks must be loaded in a `jupyter notebook` or `jupyter lab` launched within the <b><span style=\"color: rgb(100, 151, 202);\" >pyml</span></b> PVE specially created for the session.    \n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a18e3",
   "metadata": {},
   "source": [
    "# 1 $-$ The *Case Western Reserve University* bearing dataset\n",
    "\n",
    "The bearing data used in this notebook are provided by the **Case Western Reserve University (CWRU)** on the page [engineering.case.edu/bearingdatacenter/48k-drive-end-bearing-fault-data](https://engineering.case.edu/bearingdatacenter/48k-drive-end-bearing-fault-data) . <br>\n",
    "\n",
    "The data were collected from a motor driving mechanical system under four different loads with the sampling frequency of 48 kHz:<br>\n",
    "![sdsdv](./img/CWRU-TestBench.png)<br>\n",
    "(source: https://engineering.case.edu/bearingdatacenter/apparatus-and-procedures)\n",
    "\n",
    "The bearing data set was obtained under four experimental conditions:\n",
    "- Normal condition (N)\n",
    "- with Outer race Fault (OF)\n",
    "- with Inner race Fault (IF)\n",
    "- with Roller Fault (OF).\n",
    "\n",
    "Faulted bearings were installed into the test motor and vibration data was recorded for motor loads of 0 to 3 horsepower (motor speeds of 1797 to 1720 RPM).<br>\n",
    "The faults were introduced into the drive-end bearing of the motor with fault diameters of 0.18, 0.36 and 0.54 mm, respectively.\n",
    "\n",
    "The defaults classification table is as follows:\n",
    "\n",
    "|class label|Fault type|Fault diameter|\n",
    "|:---------:|:--------:|-------------:|\n",
    "| 1         | N        | 0            |\n",
    "| 2         | RF       | 0.18         |\n",
    "| 3         | RF       | 0.36         |\n",
    "| 4         | RF       | 0.54         |\n",
    "| 5         | IF       | 0.36         |\n",
    "| 6         | IF       | 0.36         |\n",
    "| 7         | IF       | 0.54         |\n",
    "| 8         | OF       | 0.18         |\n",
    "| 9         | OF       | 0.36         |\n",
    "| 10        | OF       | 0.54         |\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae6ca7",
   "metadata": {},
   "source": [
    "## 1.1 $-$ Download the the **CWRU** dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ed9a3",
   "metadata": {},
   "source": [
    "The **CWRU** dataset consists in about fifty [Matlab MAT-file](https://www.mathworks.com/help/matlab/import_export/mat-file-versions.html) files that can be downloaded:\n",
    "\n",
    "- either **manually**: by clicking on the hyper-links in the page  https://engineering.case.edu/bearingdatacenter/48k-drive-end-bearing-fault-data\n",
    "- either with **Python instruction**: for example with the *wget* module, to get the `.mat` files form the directory https://engineering.case.edu/sites/default/files.\n",
    "\n",
    "By exploring the hyper-links of the page https://engineering.case.edu/bearingdatacenter/48k-drive-end-bearing-fault-data one can define the list of the .mat files involved by the previous defaults classification table:\n",
    "\n",
    "    ['98.mat', '99.mat' '100.mat', '110.mat', '111.mat', '112.mat', '123.mat', '124.mat', '125.mat', '136.mat', '137.mat', '138.mat', '175.mat', '176.mat', '177.mat', '190.mat', '191.mat', '192.mat', '202.mat', '203.mat', '204.mat', '214.mat', '215.mat', '217.mat', '227.mat', '228.mat', '229.mat', '239.mat', '240.mat', '241.mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of the wanted '.mat' files:\n",
    "CWRU_data_file = ['98.mat', '99.mat', '100.mat', \n",
    "                  '110.mat', '111.mat', '112.mat', \n",
    "                  '123.mat', '124.mat', '125.mat', \n",
    "                  '136.mat', '137.mat', '138.mat', \n",
    "                  '175.mat', '176.mat', '177.mat', \n",
    "                  '190.mat', '191.mat', '192.mat', \n",
    "                  '202.mat', '203.mat', '204.mat', \n",
    "                  '214.mat', '215.mat', '217.mat', \n",
    "                  '227.mat', '228.mat', '229.mat', \n",
    "                  '239.mat', '240.mat', '241.mat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ea35c",
   "metadata": {},
   "source": [
    "#### The following cell lets you download all the required `.mat` files from _engineering.case.edu_ with some Python instructions.\n",
    "\n",
    "#### $\\leadsto$ If the download of the `mat` files is too slow, you can use the `mat` files already downloaded in the `pre_loaded_dataset` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f705c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "from time import sleep\n",
    "\n",
    "# the URL where to find the .mat files:\n",
    "url = 'https://engineering.case.edu/sites/default/files'\n",
    "\n",
    "# the directory where to store the downloaded files:\n",
    "data_dir = \"./CWRU_dataset/\"\n",
    "if not os.path.exists(data_dir): os.mkdir(data_dir)\n",
    "\n",
    "# download the files and store tem:\n",
    "for file in CWRU_data_file:\n",
    "    file_url = url + \"/\" + file\n",
    "    target   = os.path.join(data_dir, file)\n",
    "    if not os.path.exists(target):\n",
    "        print(f\"downloading file <{file_url}> as <{target}>\")\n",
    "        try:\n",
    "            wget.download(file_url, target) \n",
    "        except:\n",
    "            print(f\"a problem occured when loading <{file_url}>\")\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(f\"file <{target} already exists>\")\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb4c4b",
   "metadata": {},
   "source": [
    "#### $\\leadsto$ Now choose your working data directory: pre_loaded_dataset or CWRU_dataset download bty yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99196c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#### Uncomment one of the two lines:\n",
    "####\n",
    "\n",
    "#data_dir = \"./pre_loaded_dataset\"    # uncomment to use the pre-loaded CWRU dataset\n",
    "\n",
    "#data_dir = \"./CWRU_dataset\"         # uncomment to use the CWRU dataset you have loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1610581",
   "metadata": {},
   "source": [
    "Let's check the list of the `.mat` data files that are in your `data_dir` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812ecc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_mat_file = [ f for f in os.listdir(data_dir) if f.endswith(\".mat\")]\n",
    "list_mat_file.sort()\n",
    "print(f\"List of .mat files in <{data_dir}>:\\n{list_mat_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e5839",
   "metadata": {},
   "source": [
    "## 1.2 $-$ handling of the **CWRU** dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e48241",
   "metadata": {},
   "source": [
    "The `scipy.io.loadmat` can load a `.mat` file (*MAT-file* format < 7.3) and return the data as a Python `dict` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23386cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join(data_dir, \"98.mat\")\n",
    "\n",
    "mat98 = scipy.io.loadmat(data_file)  \n",
    "mat98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740fd37d",
   "metadata": {},
   "source": [
    "You can see in the above cell that the return of `loadmat` is a Python dictionary, so let's look at its **keys**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat98.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70603994",
   "metadata": {},
   "source": [
    "The accelerometers data are associated with the keys:<br>\n",
    "- `X098_DE_time`: temporal data of the accelerometer at Drive End (DE) of the test bench, sampled at 48 kHz<br>\n",
    "- `X098_FE_time`: temporal data of the accelerometer at Fan End (FE) of the test bench, sampled at 48 kHz.<br><br>\n",
    "\n",
    "The Accelerometer data in the dictionnary are `numpy.ndarray` objets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767416a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mat98['X098_DE_time']), type(mat98['X098_FE_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689124cf",
   "metadata": {},
   "source": [
    "The arrays are _single column matrices_ of accelerometers output sampled at 48 khz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a491865",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat98['X098_DE_time'].shape, mat98['X098_FE_time'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2c911",
   "metadata": {},
   "source": [
    "## 1.3 $-$ Minimalist plot of data (`pyplot` style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75752e9d",
   "metadata": {},
   "source": [
    "For simplicity, let's name `X_DE` and `X_FE` the accelerometers data and plot the data in 2 subplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DE, X_FE = mat98['X098_DE_time'], mat98['X098_FE_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e8a94",
   "metadata": {},
   "source": [
    "The cell bellow draw simple plots of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(X_DE[-2000:], '.-b', markersize=0.6)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(X_FE[-2000:], '.-m', markersize=0.6)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85587aad",
   "metadata": {},
   "source": [
    "## 1.4 $-$ More elaborate plot of data (`Axes` object style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc999c",
   "metadata": {},
   "source": [
    "In the cell bellow, we use the Matplotlib `Axes` syntaxe to draw more elaborated plots of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's compute a time vector for abscissa:\n",
    "N = 4000                 # we take only the last 4000 temporal data points\n",
    "T = np.arange(N)/48e3\n",
    "T *= 1e3                 # cconvert T in milli-sec\n",
    "\n",
    "key_DE, key_FE = 'X098_DE_time', 'X098_FE_time'\n",
    "X_DE, X_FE = mat98[key_DE], mat98[key_FE]\n",
    "\n",
    "# min and max values for plotting:\n",
    "max_value = max(X_DE[-N:].max(), X_FE[-N:].max())\n",
    "min_value = min(X_DE[-N:].min(), X_FE[-N:].min())\n",
    "\n",
    "# subplots returns a figure and a list of Axes:\n",
    "fig, axes = plt.subplots(2,1, sharex=True) \n",
    "\n",
    "fig.suptitle(f\"Accelerometers output from file <{os.path.basename(data_file)}>\")\n",
    "fig.set_size_inches((12,5))\n",
    "\n",
    "axe = axes[0]\n",
    "axe.plot(T, X_DE[-N:], '-b', markersize=0.6, linewidth=0.5, label=key_DE)\n",
    "axe.set_ylabel(\"Arbitrary unit\")\n",
    "axe.set_ylim(min_value, max_value)\n",
    "axe.legend(loc='upper right', framealpha=0.5)\n",
    "axe.grid()\n",
    "\n",
    "axe = axes[1]\n",
    "axe.plot(T, X_FE[-N:], '-m', markersize=0.6, linewidth=0.4, label=key_FE)\n",
    "axe.set_ylabel(\"Arbitrary unit\")\n",
    "axe.set_xlabel(\"Time [ms]\")\n",
    "axe.set_ylim(min_value, max_value)\n",
    "axe.legend(loc='upper right', framealpha=0.5)\n",
    "axe.grid()\n",
    "\n",
    "plt.savefig(\"CWRU_data.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1a9d80",
   "metadata": {},
   "source": [
    "## 1.5 $-$ Creating the numpy dataset from CWRU MAT-files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725933f1",
   "metadata": {},
   "source": [
    "Now let's define 3 datasets `A`, `B` and `C` by grouping the data for motor loads 1, 2 and 3: the figures bellow shows how the data of the .mat files are groupes, and the structure of the A,B and C arrays.\n",
    "\n",
    "![img/A-B-C.png](img/A-B-C.png)\n",
    "\n",
    "![img/A-B-C.png](img/array_A.png)\n",
    "\n",
    "The cell bellow creates the 3 ndarrays A, B & C and fills the arrays with the data from the .mat files as explained by the two figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5851b44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# group the CWRU files number in 3 datasets for the the motor loads 1, 2 and 3 horsepower:\n",
    "num_load_1 = ( 98, 123, 190, 227, 110, 175, 214, 136, 202, 239)\n",
    "num_load_2 = ( 99, 124, 191, 228, 111, 176, 215, 137, 203, 240)\n",
    "num_load_3 = (100, 125, 192, 229, 112, 177, 217, 138, 204, 241)\n",
    "\n",
    "# We will define 3 arrays A, B and C for the 3 datasets above: \n",
    "# for each of the 10 health condidion we will split each of the 3 datasets in 200 samples of 1900 points.\n",
    "# >>> So the shape of each array is: (10, 200, 1900):\n",
    "\n",
    "nb_HC       = 10        # number of Health Condition\n",
    "nb_sample   = 200       # number of sample batch\n",
    "sample_size = 1900      # number of data in a sample\n",
    "\n",
    "A = np.zeros((nb_HC, nb_sample, sample_size), dtype=float)\n",
    "B = np.zeros((nb_HC, nb_sample, sample_size), dtype=float)\n",
    "C = np.zeros((nb_HC, nb_sample, sample_size), dtype=float)\n",
    "\n",
    "# Now we loop simultaneously accross the files numbers and the dataset arrays to fill the arrays\n",
    "# with the files data:\n",
    "for num_load, target_array in zip((num_load_1, num_load_2, num_load_3), (A, B, C)):\n",
    "    \n",
    "    for hc, file_num in enumerate(num_load):\n",
    "        # 'hc' is the health condition rank in [0,9]\n",
    "            \n",
    "        # build the 'mat' file path with 'file_num':\n",
    "        mat_file = os.path.join(data_dir,f\"{file_num}.mat\")\n",
    "        print(f\"Loading file <{mat_file:8s}>\")\n",
    "        \n",
    "        # load the data of the file in the dict 'data':\n",
    "        data = scipy.io.loadmat(mat_file) \n",
    "        \n",
    "        # build the key and get the data we want from the dictionnary:\n",
    "        key = f\"X{file_num:03d}_DE_time\"\n",
    "        X = data[key]\n",
    "        print(f'\\t got values for key {key}, X.shape:{X.shape}')\n",
    "        \n",
    "        # Try to split the data acroos the array dimensions:\n",
    "        try:\n",
    "            for s in range(nb_sample):\n",
    "                # s is the sample number, hc is the health condition rank in [0,9]\n",
    "                target_array[hc, s] = X[s*sample_size:(s+1)*sample_size, 0]\n",
    "            print(f'\\t target array filled with data')\n",
    "        except:\n",
    "            print(f\"\\t Error with file <{file_num}.mat>\")\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a311b",
   "metadata": {},
   "source": [
    "## 1.6 $-$ Plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24340567",
   "metadata": {},
   "source": [
    "Here we will plot the data for sample #0 of the 3 arrays A, B & C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecec436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of the health condition labels:\n",
    "health_cond = ['N']\n",
    "for def_type in 'RF', 'IF', 'OF':\n",
    "    for size in '18', '36', '54':\n",
    "        health_cond.append(f\"{def_type}.{size}\")\n",
    "print(f\"list of {len(health_cond)} health conditions:\", health_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1c95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 'nb_HC', the number of health conditions:\n",
    "nb_HC = len(health_cond)\n",
    "\n",
    "# define 'nb_L', the number of load cases:\n",
    "full_dataset = (A, B, C)\n",
    "nb_L = len(full_dataset)\n",
    "\n",
    "s_num = 0  # the sample number\n",
    "\n",
    "plt.rcParams['font.size'] = 6   # change the pyplot defaut font size\n",
    "fig, axes = plt.subplots(nb_HC, nb_L, sharex=True)\n",
    "fig.set_size_inches((8,12))\n",
    "plt.subplots_adjust(top=.95, wspace=0.25, hspace=0.5)\n",
    "plt.suptitle(f\"Plots for the sample #{s_num}\", fontsize=10)\n",
    "\n",
    "for n, dataset in enumerate(full_dataset):\n",
    "    for hc in range(nb_HC):\n",
    "        axe = axes[hc, n]\n",
    "        axe.set_title(f\"Load_{n+1} / health cond {health_cond[hc]}\", fontsize=8)\n",
    "        axe.plot(dataset[hc, s_num], linewidth=0.4)\n",
    "        if hc == nb_HC-1: axe.set_xlabel(\"Rank\")\n",
    "\n",
    "plt.rcParams['font.size'] = 10  # restore the pyplot defaut font size to its defautl value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d97ff9",
   "metadata": {},
   "source": [
    "## 1.7 $-$ Export the numpy dadasets in a `.npz` compressed file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad813c1",
   "metadata": {},
   "source": [
    "The function `savez` of `numpy` takes `ndarray` objects as arguments and creates a binary file that holds the arrays data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff7372",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('CWRU_dadaset', A, B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f7a19",
   "metadata": {},
   "source": [
    "### Further work:\n",
    "In the next notebook (`2-process_CWRU_data.ipynb`), you will load the `CWR_dataset.npz` file and learn how to pre-process the dataset in order to prepare the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2789298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
