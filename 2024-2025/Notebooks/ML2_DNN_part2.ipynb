{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:10pt\">AI-ML @ ENSPIMA / v1.2 september 2024 / Jean-Luc CHARLES (Jean-Luc.charles@mailo.com) / CC BY-SA 4.0 /</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:brown;font-family:arial;font-size:26pt;font-weight:bold;text-align:center\"> \n",
    "Machine learning with Python tensorflow2/keras modules</div><br>\n",
    "<hr>\n",
    "<div style=\"color:blue;font-family:arial;font-size:22pt;font-weight:bold;text-align:center\"> \n",
    "Training a Dense Neural Network to classify handwritten digits<br><br>\n",
    "DNN-Part-2 : Load & evaluate the trained Network</div>\n",
    "<hr>\n",
    "Expected duration : 15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<span style=\"color:brown;font-family:arial;font-size:12pt\"> \n",
    "It is important to use a <span style=\"font-weight:bold;\">Python Virtual Environment</span> (PVE) for your Python projects: a PVE makes it possible to control for each project the versions of the Python interpreter and the \"sensitive\" modules (like tensorflow).</span></div>\n",
    "\n",
    "All the notebooks must be loaded in a `jupyter notebook` or `jupyter lab` launched within the <b><span style=\"color: rgb(200, 151, 102);\" >pyml</span></b> PVE specially created for the session.<br>\n",
    "They should be worked in this order:\n",
    "- `ML1_MNIST.ipynb`: check that the <b><span style=\"color: rgb(200, 151, 102);\">pyml</span></b> PVE is fuly operationnal, load and use the data from the MNIST database (images and labels).\n",
    "- `ML2_DNN_part1.ipynb`: build a Dense Neural Network (DNN), train it with data from the MNIST and evaluate its performance.\n",
    "- `ML2_DNN_part2.ipynb`: reload a previously trained DNN and evaluate its performance with the MNIST test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted learning objectives\n",
    "Know how to:\n",
    "- reload the structure and the weights of a previously trained DNN.\n",
    "- exploit the reloaded trained DNN with the `predict` method.\n",
    "- display and use the matrix of confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Verify importing Python modules\n",
    "The **keras** module which allows high-level manipulation of **tensorflow** objects is integrated in the **tensorflow** (tf) module since version 2. <br>\n",
    "The **tf.keras** module documentation to consult is here: https://www.tensorflow.org/api_docs/python/tf/keras.\n",
    "\n",
    "Importing the `tensorflow` module in the cell below may generate some warning messages...<br>\n",
    "if errors appear they must be corrected, possibly by recreating your PVE <b><span style=\"color: rgb(200, 51, 102);\">pyml-pm</span></b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, cv2\n",
    "\n",
    "# Delete the (numerous) warning messages from the **tensorflow** module:\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Python    : {sys.version.split()[0]}\")\n",
    "print(f\"tensorflow: {tf.__version__} incluant keras {keras.__version__}\")\n",
    "print(f\"numpy     : {np.__version__}\")\n",
    "print(f\"OpenCV    : {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding matplotlib plots in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder of the structure of the DNN\n",
    "\n",
    "In this notebook we use a **Dense Neural Network** , with:\n",
    "- an **input layer** of 784 values between 0 and 1 (the pixels of the MNIST 28 $\\times$ 28 images flattened to a normalized vector of 784 `float` numbers),\n",
    "- a **hidden layer** of 784 neurons with the `relu` activation function,\n",
    "- an **output layer** of 10 neurons for the classification of images into 10 classes associated with the digits {0,1,2...9}, using the `softmax` activation function adapted to classification problems.\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/ReseauChiffres-2_transp.png\" alt=\"archiNetwork.png\" style=\"width:900px;\"><br>\n",
    "    [image credit: JLC]\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<hr>\n",
    "\n",
    "## Work to do\n",
    "### 1 - Load and pre-process the MNIST test data set\n",
    "### 2 - Reload the trained DNN structure and its weights\n",
    "### 3 - Exploit the trained DNN with predict method\n",
    "### 4 - Display the matrix of confusion\n",
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 - Load and pre-process MNIST test data set\n",
    "\n",
    "The work of loading and pre-processing the MNIST images has already been seen in the *notebooks*  `3-ML1_MNIST.ipynb` and `4-ML2_DNN_part1.ipynb`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data set:\n",
    "(im_train, lab_train), (im_test, lab_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Define parameters :\n",
    "nb_im_test  = im_test.shape[0]     # number of test images\n",
    "nb_pixel    = im_test[0].size      # number of pixels per image\n",
    "nb_class   = len(set(lab_test))    # number of classes (10 digits from 0 to 9)\n",
    "\n",
    "print(f\"{nb_im_test} test images\")\n",
    "print(f\"{nb_pixel} pixels in each image\")\n",
    "print(f\"{nb_class} classes (the digits from 0 to 9)\")\n",
    "\n",
    "# Flatten and normalize matrixes:\n",
    "x_test  = im_test.reshape(nb_im_test, nb_pixel)/im_test.max()\n",
    "\n",
    "# 'one-hot' encoding of the labels:\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test  = to_categorical(lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Reload the trained network structure and weights\n",
    "\n",
    "The `loadl` method of the `tf.keras.models` class reloads **the structure** and **the weights** of a trained network.<br>\n",
    "So you can build __and__ relod the DNN trained in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check wether the 'model' directory exist (create it if needed):\n",
    "if not os.path.exists(\"models\"): os.mkdir(\"models\")\n",
    "\n",
    "# define a uniq key:\n",
    "key = 'dense1_trained'\n",
    "\n",
    "# define the path where to store the network data:\n",
    "path = os.path.join('models', key)\n",
    "\n",
    "# load the DNN structure and weights:\n",
    "model = tf.keras.models.load_model(path)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3 - Exploiting the trained network: `predict` method\n",
    "\n",
    "The `predict` method is used to compute the DNN inferences for one or more inputs (see the `predict` method in the page \n",
    "[tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict)).\n",
    "\n",
    "The cell below shows an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 100  # number of the test image \n",
    "\n",
    "# display the image:\n",
    "from utils.tools import plot_images\n",
    "plot_images(im_test,1,1,i) ; plt.show()\n",
    "\n",
    "# compute the trained DNN inference inférence for tes test image:\n",
    "rep = model.predict(x_test[i:i+1])      # Warning: x must be an array of matrixes, not a simple matrix\n",
    "                                        # => x[i] does not work!\n",
    "\n",
    "print(f\"DNN inférence for the test image #{i} :\\n{rep[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the output of the network more readable, we can limit the display of the numpy array to 2 decimal places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with np.printoptions(formatter={'float':'{:.2f}'.format}):    \n",
    "    print(f\"DNN inférence for the test image #{i} rounded to 2 digits:\\n{rep[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `argmax` method of the *ndarray* class of *numpy* gives the rank of the maximum value in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicted label is rep[0].argmax(): {rep[0].argmax()}\")\n",
    "print(f\"Actual label of the test image #{i} : {lab_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\leadsto$ The usefulness of numpy `argmax` method to decode the array of *one-hot* vectors returned by `predict`\n",
    "\n",
    "When you compute inferences of the DNN for the images of the `x_test` array for example, you get an array of *one-hot* vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(x_test)\n",
    "print(\"shape of the 'results' ndarray:\", results.shape)\n",
    "print(\"Example of of vectors in the 'result' ndarray:\")\n",
    "with np.printoptions(formatter={'float':'{:.2f}'.format}): \n",
    "    print(\"\\t First test image -> results[0]  :\", results[0])\n",
    "    print(\"\\t Last test image  -> results[-1] :\", results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the expression `results.argmax(axe=-1)`, you get the array of the `argmax` of each vector $\\leadsto$ the array of the classes computed by the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences = results.argmax(axis=-1)\n",
    "print(f\"inferences.shape: {inferences.shape}, inferences.dtype: {inferences.dtype}\")\n",
    "print(f\"Content of 'inferences': {inferences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare `inferences` and `lab_test` with the `==` operator (it makes sense with *ndarray* objects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences == lab_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by counting the number of `True` we get the number of correct inferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_ok = (inferences == lab_test)\n",
    "print(f\"number of true inferences: {inference_ok.sum()} over {nb_im_test} test images\")\n",
    "\n",
    "precision = inference_ok.sum()/nb_im_test*100\n",
    "print(f\"precision of the trained DNN: {precision:.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4 - Show Confusion Matrix\n",
    "\n",
    "The `ConfusionMatrixDisplay.from_predictions` function from the `sklearn.metrics` module displays the **confusion matrix** to visualize:\n",
    "- on the diagonal: the correct inferences of the DNN, with the number of correct answers in each box\n",
    "- off diagonal: the DNN errors, with the number of occurrences in each box.\n",
    "\n",
    "The documentation for the confusion matrix in the `scikit-learn` module is here : [scikit-learn.org/stable/modules/.../ConfusionMatrixDisplay.from_predictions](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "axis = plt.axes()\n",
    "ConfusionMatrixDisplay.from_predictions(lab_test, inferences, cmap='magma', ax=axis, colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Other interesting resources... videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/trWrEWfhTVg\" width=\"400\" height=\"300\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/trWrEWfhTVg\" width=\"400\" height=\"300\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/aircAruvnKk\" width=\"400\" height=\"300\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/aircAruvnKk\" width=\"400\" height=\"300\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/IHZwWFHWa-w\"width=\"400\" height=\"300\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/IHZwWFHWa-w\"width=\"400\" height=\"300\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/Ilg3gGewQ5U\" width=\"400\" height=\"300\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/Ilg3gGewQ5U\" width=\"400\" height=\"300\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
